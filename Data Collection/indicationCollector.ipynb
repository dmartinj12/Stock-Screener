{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b2b70d-59f5-4a82-8298-3f94af4d56e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import yfinance as yf\n",
    "import talib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71c09c89-db5f-4b0b-b768-6ab77281186a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Volume</th>\n",
       "      <th>outstandingShares</th>\n",
       "      <th>avgVolume</th>\n",
       "      <th>recentVolume</th>\n",
       "      <th>turnoverRatio</th>\n",
       "      <th>relativeVolume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>4669843600</td>\n",
       "      <td>24490000384</td>\n",
       "      <td>222373505</td>\n",
       "      <td>164414000</td>\n",
       "      <td>0.190684</td>\n",
       "      <td>0.739360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACHR</td>\n",
       "      <td>870590100</td>\n",
       "      <td>389161984</td>\n",
       "      <td>41456671</td>\n",
       "      <td>51919400</td>\n",
       "      <td>2.237089</td>\n",
       "      <td>1.252377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BITF</td>\n",
       "      <td>1066518500</td>\n",
       "      <td>472500000</td>\n",
       "      <td>50786595</td>\n",
       "      <td>45872800</td>\n",
       "      <td>2.257182</td>\n",
       "      <td>0.903246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2152430700</td>\n",
       "      <td>3210060032</td>\n",
       "      <td>102496700</td>\n",
       "      <td>58267200</td>\n",
       "      <td>0.670527</td>\n",
       "      <td>0.568479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PLUG</td>\n",
       "      <td>1460352600</td>\n",
       "      <td>911196992</td>\n",
       "      <td>69540600</td>\n",
       "      <td>90739700</td>\n",
       "      <td>1.602675</td>\n",
       "      <td>1.304845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker      Volume  outstandingShares  avgVolume  recentVolume  \\\n",
       "0   NVDA  4669843600        24490000384  222373505     164414000   \n",
       "1   ACHR   870590100          389161984   41456671      51919400   \n",
       "2   BITF  1066518500          472500000   50786595      45872800   \n",
       "3   TSLA  2152430700         3210060032  102496700      58267200   \n",
       "4   PLUG  1460352600          911196992   69540600      90739700   \n",
       "\n",
       "   turnoverRatio  relativeVolume  \n",
       "0       0.190684        0.739360  \n",
       "1       2.237089        1.252377  \n",
       "2       2.257182        0.903246  \n",
       "3       0.670527        0.568479  \n",
       "4       1.602675        1.304845  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "screened_df = pd.read_csv('../Resources/Filtererd_by_Liquidity.csv')\n",
    "screened_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e0800aa-5765-4201-b3c6-34f0c804e1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers = screened_df[\"Ticker\"]\n",
    "len(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b40b825-3b50-4ab5-b7ba-c00dc6a83907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for NVDA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for ACHR...\n",
      "Downloading data for BITF...\n",
      "Downloading data for TSLA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for PLUG...\n",
      "Downloading data for INTC...\n",
      "Downloading data for LCID...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for PLTR...\n",
      "Downloading data for SOFI...\n",
      "Downloading data for NIO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for IREN...\n",
      "Downloading data for OPEN...\n",
      "Downloading data for DELL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for GRAB...\n",
      "Downloading data for NU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for AMD...\n",
      "Downloading data for F...\n",
      "Downloading data for PFE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for HPQ...\n",
      "Downloading data for IQ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for RKLB...\n",
      "Downloading data for WBD...\n",
      "Downloading data for KSS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for QBTS...\n",
      "Downloading data for SYM...\n",
      "Downloading data for GOLD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for JOBY...\n",
      "Downloading data for AMCR...\n",
      "Downloading data for DNN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for GGB...\n",
      "Downloading data for MU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for AES...\n",
      "Downloading data for BB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for HPE...\n",
      "Downloading data for APLT...\n",
      "Downloading data for HOOD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for AMC...\n",
      "Downloading data for XPEV...\n",
      "Downloading data for AAL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for SNAP...\n",
      "Downloading data for WDAY...\n",
      "Downloading data for WBA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for AU...\n",
      "Downloading data for KGC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for LX...\n",
      "Downloading data for UBER...\n",
      "Downloading data for RIG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for BZ...\n",
      "Downloading data for AGNC...\n",
      "Downloading data for BE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for YMM...\n",
      "Downloading data for BTG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for GM...\n",
      "Downloading data for RXRX...\n",
      "Downloading data for SMR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for CRWD...\n",
      "Downloading data for APLD...\n",
      "Downloading data for WDC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for HL...\n",
      "Downloading data for ZIM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for BTE...\n",
      "Downloading data for LUMN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for PTON...\n",
      "Downloading data for MAC...\n",
      "Downloading data for CNH...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for JBLU...\n",
      "Downloading data for CIFR...\n",
      "Downloading data for PDD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for OWL...\n",
      "Downloading data for NOVA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for CCL...\n",
      "Downloading data for XP...\n",
      "Downloading data for MPW...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for BBAI...\n",
      "Downloading data for HBAN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for HSAI...\n",
      "Downloading data for LESL...\n",
      "Downloading data for MRVL...\n",
      "Downloading data for PAGS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for NKE...\n",
      "Downloading data for TNYA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for CLF...\n",
      "Downloading data for AG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for AUR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for ZETA...\n",
      "Downloading data for NGD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for URBN...\n",
      "Downloading data for NFE...\n",
      "Downloading data for HAL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for LRCX...\n",
      "Downloading data for NTNX...\n",
      "Downloading data for JWN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for HIVE...\n",
      "Downloading data for CVS...\n",
      "Downloading data for KODK...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for API...\n",
      "Downloading data for STNE...\n",
      "Downloading data for GAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for CDE...\n",
      "Downloading data for RCAT...\n",
      "Downloading data for VRT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for VSH...\n",
      "Downloading data for FCX...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for NEM...\n",
      "Downloading data for HST...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for OXY...\n",
      "Downloading data for AFRM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for TGT...\n",
      "Downloading data for KHC...\n",
      "Downloading data for ARWR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for SQ...\n",
      "Downloading data for AMGN...\n",
      "Downloading data for FLNC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "data_frames = {}  # Dictionary to store valid DataFrames\n",
    "invalid_tickers = []  # List to keep track of faulty tickers\n",
    "\n",
    "for ticker in tickers[:]:\n",
    "    try:\n",
    "        print(f\"Downloading data for {ticker}...\")\n",
    "        data = yf.download(ticker, period='6mo', interval='1d')\n",
    "        \n",
    "        # Check if data was successfully fetched\n",
    "        if data.empty:\n",
    "            invalid_tickers.append(ticker)\n",
    "        else:\n",
    "            data_frames[ticker] = data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading data for {ticker}: {e}\")\n",
    "        invalid_tickers.append(ticker)\n",
    "\n",
    "# Remove invalid tickers from the list\n",
    "tickers = [ticker for ticker in tickers if ticker not in invalid_tickers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc24b56e-36f6-44ba-84b2-c483de9b2187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store calculated values\n",
    "VWAP = []\n",
    "training_VWAP = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        # Access the DataFrame for the current ticker\n",
    "        df = data_frames[ticker]\n",
    "\n",
    "        # Calculate VWAP\n",
    "        df['VWAP'] = (df['Close'] * df['Volume']).cumsum() / df['Volume'].cumsum()\n",
    "\n",
    "        # Calculate previous day's VWAP\n",
    "        df['Training VWAP'] = df['VWAP'].shift(1)\n",
    "\n",
    "        # Append the final VWAP value and previous VWAP to the lists\n",
    "        VWAP.append(df['VWAP'].iloc[-1])\n",
    "        training_VWAP.append(df['Training VWAP'].iloc[-1])\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating VWAP for {ticker}: {e}\")\n",
    "        VWAP.append(None)\n",
    "        training_VWAP.append(None)\n",
    "\n",
    "# Create a DataFrame for VWAP results\n",
    "VWAP_df = pd.DataFrame({\n",
    "    \"Ticker\": tickers, \n",
    "    \"VWAP\": VWAP, \n",
    "    \"Training VWAP\": training_VWAP\n",
    "})\n",
    "\n",
    "# Display results\n",
    "VWAP_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee464c0-de3c-4769-917b-c5a355f5566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store calculated values\n",
    "recent_closes = []\n",
    "training_closes = []\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        # Access the DataFrame for the current ticker\n",
    "        df = data_frames[ticker]\n",
    "\n",
    "        # Get the most recent closing price (last value)\n",
    "        recent_close = df['Close'].iloc[-1].values[0]\n",
    "        training_close = df['Close'].iloc[-2].values[0]\n",
    "        recent_closes.append(recent_close)\n",
    "        training_closes.append(training_close)\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting recent close for {ticker}: {e}\")\n",
    "        recent_closes.append(None)\n",
    "        training_closes.append(None)\n",
    "\n",
    "# Create a DataFrame for recent closing prices\n",
    "VWAP_df = pd.DataFrame({\"Ticker\": tickers, \"VWAP\":VWAP,   \n",
    "                        \"Training VWAP\": training_VWAP,\n",
    "                        \"Recent Close\": recent_closes,\n",
    "                        \"Training Close\": training_closes})\n",
    "\n",
    "# Display the DataFrame with recent closing prices\n",
    "VWAP_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2918d94-99bf-4a91-abc0-8a64ab47b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store calculated values\n",
    "momentum = []\n",
    "training_momentum = []\n",
    "# Iterate over the rows of the VWAP dataframe to calculate momentum\n",
    "for index, row in VWAP_df.iterrows():\n",
    "    ticker = row['Ticker']\n",
    "    recent_close = row['Recent Close']\n",
    "    training_recent_close = row[\"Training Close\"]\n",
    "    vwap = row['VWAP']\n",
    "    training_vwap = row[\"Training VWAP\"]\n",
    "    \n",
    "    # Calculate momentum (percentage difference between recent close and VWAP)\n",
    "    if vwap != 0:\n",
    "        momentum_value = (recent_close - vwap) / vwap\n",
    "        training_momentum_value = (training_recent_close - training_vwap) / training_vwap\n",
    "    else:\n",
    "        momentum_value = 0\n",
    "        training_momentum_value = 0\n",
    "    momentum.append(momentum_value)\n",
    "    training_momentum.append(training_momentum_value)\n",
    "\n",
    "# Add momentum to VWAP_df\n",
    "VWAP_df['Momentum'] = momentum\n",
    "VWAP_df['Training Momentum'] = training_momentum\n",
    "VWAP_df['Momentum (%)'] = VWAP_df['Momentum'] * 100\n",
    "VWAP_df['Training Momentum (%)'] = VWAP_df['Training Momentum'] * 100\n",
    "\n",
    "# Display the updated dataframe\n",
    "VWAP_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fb3749-a85b-4792-b1bc-3aa854f367bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib\n",
    "\n",
    "crossover_results = []\n",
    "\n",
    "# Loop through each ticker in the data_frames\n",
    "for ticker, data in data_frames.items():\n",
    "    # Convert the 'Close' column to a 1D numpy array\n",
    "    close_prices = data['Close'].to_numpy().flatten()\n",
    "\n",
    "    # Ensure close_prices is 1D before passing it to MACD\n",
    "    if close_prices.ndim == 1:\n",
    "        # Calculate MACD and Signal line using talib\n",
    "        macd, macd_signal, macd_hist = talib.MACD(close_prices, fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "\n",
    "        # Check for crossovers\n",
    "        crossover = []\n",
    "        for i in range(1, len(macd)):\n",
    "            if macd[i-1] < macd_signal[i-1] and macd[i] > macd_signal[i]:  # Bullish crossover\n",
    "                crossover.append('Bullish')\n",
    "            elif macd[i-1] > macd_signal[i-1] and macd[i] < macd_signal[i]:  # Bearish crossover\n",
    "                crossover.append('Bearish')\n",
    "            else:\n",
    "                crossover.append(None)\n",
    "\n",
    "        # Add MACD, Signal, and Crossover columns to the DataFrame\n",
    "        data['MACD'] = macd\n",
    "        data['Signal'] = macd_signal\n",
    "        data['Crossover'] = [None] + crossover  # Align crossover with data length\n",
    "\n",
    "        # Reverse the DataFrame for easier processing of recent events\n",
    "        reversed_data = data.iloc[::-1]\n",
    "\n",
    "        # Find the last two crossovers\n",
    "        crossovers = reversed_data[reversed_data['Crossover'].notna()]\n",
    "        if len(crossovers) == 0:\n",
    "            latest_crossover = None\n",
    "            previous_crossover = None\n",
    "            crossover_date = None\n",
    "            days_since_crossover = None\n",
    "            days_to_previous_crossover = None\n",
    "        else:\n",
    "            latest_crossover_row = crossovers.iloc[0]\n",
    "            latest_crossover = latest_crossover_row['Crossover']\n",
    "            latest_crossover_date = crossovers.iloc[0].values[0]\n",
    "            crossover_date = latest_crossover_row.name\n",
    "            days_since_crossover = (datetime.now() - pd.Timestamp(crossover_date).to_pydatetime()).days\n",
    "\n",
    "            if len(crossovers) > 1:\n",
    "                previous_crossover_row = crossovers.iloc[1]\n",
    "                previous_crossover = previous_crossover_row['Crossover']\n",
    "                training_crossover_date = crossovers.iloc[0].values[0]\n",
    "                days_since_training_crossover = (pd.Timestamp(crossover_date) - pd.Timestamp(previous_crossover_row.name)).days\n",
    "            else:\n",
    "                previous_crossover = None\n",
    "                days_to_previous_crossover = None\n",
    "\n",
    "        # Store the results\n",
    "        crossover_results.append((ticker, crossover_date, days_since_crossover, training_crossover_date, \\\n",
    "                                  days_to_previous_crossover))\n",
    "\n",
    "# Convert the results into a DataFrame for easy viewing\n",
    "crossover_df = pd.DataFrame(crossover_results, columns=[\n",
    "    'Ticker', 'Crossover Date', 'Days Since Crossover', 'Training Crossover', 'Days to Previous Crossover'\n",
    "])\n",
    "crossover_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852b3498-329e-410e-b202-9de2d390f55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_data = reversed_data.iloc[1:]\n",
    "\n",
    "reversed_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09885536-3100-4264-a362-b433da8843df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store RSI values for each ticker\n",
    "rsi_results = []\n",
    "training_rsi = []\n",
    "\n",
    "# Loop through each ticker in the data_frames\n",
    "for ticker, data in data_frames.items():\n",
    "    # Convert the 'Close' column to a 1D numpy array\n",
    "    close_prices = data['Close'].to_numpy().flatten() \n",
    "\n",
    "    # Calculate RSI using talib (default period is 14)\n",
    "    rsi = talib.RSI(close_prices, timeperiod=14)\n",
    "\n",
    "    # Add RSI to the dataframe for that ticker\n",
    "    data['RSI'] = rsi\n",
    "\n",
    "    # Store the latest RSI value for each ticker (for the most recent day)\n",
    "    latest_rsi = rsi[-1]\n",
    "    previous_rsi = rsi[-2]\n",
    "    rsi_results.append((ticker, latest_rsi))\n",
    "    training_rsi.append((ticker, previous_rsi))\n",
    "\n",
    "# Convert the results into a DataFrame for easy viewing\n",
    "rsi_df = pd.DataFrame(rsi_results, columns=['Ticker', 'Latest RSI'])\n",
    "training_rsi = pd.DataFrame(training_rsi, columns=['Ticker', 'Training RSI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d489dc-7c27-42f4-aabb-41c73b9e34b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the Bollinger Bands results for each ticker\n",
    "bollinger_bands = []\n",
    "training_bands = []\n",
    "\n",
    "# Loop through each ticker in your data_frames\n",
    "for ticker, data in data_frames.items():\n",
    "    # Get the closing prices\n",
    "    close_prices = data['Close'].to_numpy().flatten()\n",
    "\n",
    "    # Calculate Bollinger Bands using talib\n",
    "    upper_band, middle_band, lower_band = talib.BBANDS(close_prices, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)\n",
    "\n",
    "    # Add the Bollinger Bands to the dataframe\n",
    "    data['Upper Band'] = upper_band\n",
    "    data['Middle Band'] = middle_band\n",
    "    data['Lower Band'] = lower_band\n",
    "\n",
    "    # Store the latest values for each ticker\n",
    "    latest_upper = upper_band[-1]\n",
    "    latest_middle = middle_band[-1]\n",
    "    latest_lower = lower_band[-1]\n",
    "\n",
    "    training_upper = upper_band[-2]\n",
    "    training_middle = middle_band[-2]\n",
    "    training_lower = lower_band[-2]\n",
    "\n",
    "    bollinger_bands.append((ticker, latest_upper, latest_middle, latest_lower))\n",
    "    training_bands.append((ticker, training_upper, training_middle, training_lower))\n",
    "\n",
    "# Convert the results into a DataFrame for easy viewing\n",
    "bollinger_df = pd.DataFrame(bollinger_bands, columns=['Ticker', 'Upper Band', 'Middle Band', 'Lower Band'])\n",
    "training_bollinger = pd.DataFrame(training_bands, columns=['Ticker', 'Upper Train Band', 'Middle Train Band', 'Lower Train Band'])\n",
    "training_bollinger.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa2ca8d-0e7e-4111-a159-a12e77b1c47f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8506536f-815d-428e-a1d3-f935b03684ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "screened_df = screened_df[screened_df['Ticker'].isin(tickers)]\n",
    "screened_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ed1c4e-7ac9-461d-b23b-a88fca369698",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = VWAP_df.mrge(crossover_df, on='Ticker').merge(rsi_df, on='Ticker').merge(bollinger_df, \\\n",
    "on ='Ticker').merge(screened_df, on='Ticker')\n",
    "training_df = VWAP_df.mrge(crossover_df, on='Ticker').merge(training_rsi, on='Ticker').merge(training_bands, \\\n",
    "on ='Ticker').merge(screened_df, on='Ticker')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15cab74-2267-43db-930b-8f58871e6733",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('../Resources/ForPredictivePurposes.csv', index=False, mode='w')\n",
    "training_df.to_csv('../Resources/ForPredictiveModels.csv', index=False,mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4054909f-d757-46dc-8516-3fb6b7c69247",
   "metadata": {},
   "source": [
    "# PyMongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb76846e-b2dc-4682-8173-3883bdc0ad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# MongoDB connection\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "\n",
    "# Connect to the stockValues database\n",
    "db = client['stockValues']\n",
    "\n",
    "# Explicitly select the collection for firstRound\n",
    "first_round_collection = db['firstRound']\n",
    "\n",
    "# Explicitly select the collection for stockPrices\n",
    "stockPriceCollection = db['stockPrices']\n",
    "\n",
    "# Assuming you already have merged_df for the first insertion into 'firstRound'\n",
    "data_dict = merged_df.to_dict(orient='records')\n",
    "first_round_collection.insert_many(data_dict)\n",
    "\n",
    "# Now loop through the tickers and insert data into stockPriceCollection\n",
    "for ticker, data in data_frames.items():\n",
    "    # Reset the index and ensure column names are strings\n",
    "    data_reset = data.reset_index()\n",
    "    \n",
    "    # Ensure column names are strings (fix any issues with non-string or empty names)\n",
    "    data_reset.columns = [str(col) if col != '' else 'Unnamed_Column' for col in data_reset.columns]\n",
    "    \n",
    "    # Convert to dictionary format suitable for MongoDB\n",
    "    data_dict = data_reset.to_dict(orient='records')\n",
    "    \n",
    "    # Insert into stockPriceCollection\n",
    "    stockPriceCollection.insert_many(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fdec30-f6f1-4385-9bf1-dea5dfdbb9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52883d35-2c9c-4d22-9cfc-73cdbd2fe134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83c157e-954c-4247-bef5-c7209f70075d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
